# 概念

## 大数定律

### 随机变量序列的**依概率收敛**

​	$\mathop{lim}\limits_{n\to \infty}P\{|Y_n-a|<\epsilon\}=1$

​	记为：$Y_n \xrightarrow{P}a$

​	性质：

​		$X_n\xrightarrow{P}a,Y_n\xrightarrow{P}b,g(x,y)在点(a,b)连续，则：$

​		$g(X_n,Y_n)\xrightarrow{P}g(a,b)$

### 切比雪夫不等式

随机变量X的期望和方差存在，则对任意的$\epsilon>0$总有

$P\{|X-E(X)|\ge \epsilon\}\le \frac{D(X)}{\epsilon^2}$

### 切比雪夫大数定律

$X_i两两不相关，存在常数C使得D(X_i)\le C，则对任意\epsilon>0有：$

$\mathop{lim}\limits_{n\to +\infty}P\{|\frac{1}{n}\sum\limits_{i=1}^nX_i-\frac{1}{n}\sum\limits_{i=1}^nE(X_i)|<\epsilon\}=1$

### 伯努利大数定理

​	$\lim\limits_{n\to\infty}P\{|\frac{f_A}{n}-p|<\epsilon\}=1$	

或

​	$\lim\limits_{n\to\infty}P\{|\frac{f_A}{n}-p|\ge\epsilon\}=0$	

​	$其中，f_A是n次独立重复实验中A发生的次数，P是事件A每次实验发生的概率$

> 当实验次数足够大，就可以用频率代替概率

### 辛钦大数定理

​	$\mathop{lim}\limits_{n\to \infty}P\{|\frac{1}{n}\sum\limits_{k=1}^n X_k-\mu|<\epsilon\}=1$

>对于n个同分布的随机变量，n很大时，他们的算术平均**很可能** **接近**方差

​	其中$\overline{X}=\sum\limits_{k=1}^nX_k,依概率收敛于期望$

## 中心极限定理

### 列维-林德伯格中心极限定理

$X_1,X_2,\cdots X_n相互独立，服从同一分布，且具有数学期望\mu和方差\sigma^2$

随机变量之和的标准化变量满足：

$\mathop{lim}\limits_{n\to \infty}F_n(x)=\Phi(x)$

>也可以是
>
>$\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\sim N(0,1)$
>
>$\overline{X}\sim N(\mu,\sigma^2/n)$

### 拉普拉斯中心极限定理

列维-林德伯格中心极限定理的特殊情况：分布为二项分布的情况



